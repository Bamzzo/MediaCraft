# app/main.py
import os
import re
import uvicorn
from dotenv import load_dotenv  # ğŸ‘ˆ å¼•å…¥ dotenv

# âš ï¸ æå…¶å…³é”®ï¼šåœ¨æ‰€æœ‰ä»£ç è¿è¡Œå‰åŠ è½½ç¯å¢ƒå˜é‡ï¼
load_dotenv() 

from fastapi import BackgroundTasks, FastAPI, UploadFile, File
from pydantic import BaseModel
from typing import Optional

from langchain_core.messages import HumanMessage
from sse_starlette.sse import EventSourceResponse

from app.agent import app_graph
from app.context import current_model_config, current_image_data, current_video_data, current_vision_model

app = FastAPI(title="ByteCreator Backend")

# --- è§†è§‰å·¥åŠä¸“ç”¨ç›´è¿ API ---
class ImageRequest(BaseModel):
    prompt: str


class VideoRequest(BaseModel):
    prompt: str


@app.post("/api/generate_image")
async def api_generate_image(req: ImageRequest):
    from app.tools import generate_image

    result = generate_image.invoke({"prompt": req.prompt})
    url_match = re.search(r"\[System Hidden URL:\s*(https?://[^\s\]]+)\]", str(result))
    if url_match:
        return {"status": "success", "url": url_match.group(1)}
    return {"status": "error", "message": result}


@app.post("/api/generate_video")
async def api_generate_video(req: VideoRequest):
    from app.tools import generate_video

    result = generate_video.invoke({"prompt": req.prompt})
    url_match = re.search(r"\[System Hidden Video URL:\s*(https?://[^\s\]]+)\]", str(result))
    if url_match:
        return {"status": "success", "url": url_match.group(1)}
    return {"status": "error", "message": result}


# --- æ•°æ®æ¨¡å‹å®šä¹‰ ---
class ModelConfig(BaseModel):
    chat: str = "DeepSeek-V3 (SiliconFlow)"
    image: Optional[str] = "Flux.1"
    vision: Optional[str] = "Qwen-VL"

class ChatRequest(BaseModel):
    content: str
    thread_id: str
    system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"
    llm_config: Optional[ModelConfig] = None
    image_data: Optional[str] = None
    video_data: Optional[str] = None  # ğŸ‘ˆ æ–°å¢è§†é¢‘ Base64 æ¥æ”¶å­—æ®µ


# --- æ¥å£å®šä¹‰ ---
@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼å¯¹è¯æ¥å£ï¼Œæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢
    """
    llm_config = request.llm_config or ModelConfig()

    async def event_generator():
        token_config = current_model_config.set({"chat": llm_config.chat, "vision": llm_config.vision})
        token_img = current_image_data.set(request.image_data)
        token_vid = current_video_data.set(request.video_data)
        token_vision = current_vision_model.set(llm_config.vision)

        try:
            user_text = request.content
            if request.image_data:
                user_text = f"ã€ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·åœ¨æœ¬æ¬¡å¯¹è¯ä¸­é™„å¸¦ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡ã€‚è¯·ç«‹åˆ»è°ƒç”¨ 'analyze_uploaded_image' å·¥å…·è¿›è¡Œè§£æã€‚ã€‘\n\nç”¨æˆ·è¾“å…¥ï¼š{request.content}"
            elif request.video_data:
                user_text = f"ã€ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·åœ¨æœ¬æ¬¡å¯¹è¯ä¸­é™„å¸¦ä¸Šä¼ äº†ä¸€æ®µè§†é¢‘ã€‚è¯·ç«‹åˆ»è°ƒç”¨ 'analyze_uploaded_video' å·¥å…·è¿›è¡ŒæŠ½å¸§ä¸è§£æã€‚ã€‘\n\nç”¨æˆ·è¾“å…¥ï¼š{request.content}"

            inputs = {"messages": [HumanMessage(content=user_text)]}

            config = {
                "configurable": {
                    "thread_id": request.thread_id,
                    "selected_chat_model": llm_config.chat,
                    "system_prompt": request.system_prompt,
                }
            }

            async for event in app_graph.astream_events(inputs, config=config, version="v1"):
                kind = event["event"]

                if kind == "on_tool_start":
                    if event.get("name") == "generate_image":
                        yield {"data": "[SIGNAL_TOOL_START:generate_image]"}
                    elif event.get("name") == "analyze_uploaded_image":
                        yield {"data": "[SIGNAL_TOOL_START:analyze_image]"}
                    elif event.get("name") == "analyze_uploaded_video":
                        yield {"data": "[SIGNAL_TOOL_START:analyze_video]"}
                    elif event.get("name") == "generate_video":
                        yield {"data": "[SIGNAL_TOOL_START:generate_video]"}

                elif kind == "on_tool_end":
                    tool_name = event.get("name")
                    output = event["data"].get("output")
                    if not output:
                        pass
                    elif tool_name == "generate_image":
                        url_match = re.search(r'\[System Hidden URL:\s*(https?://[^\s\]]+)\]', str(output))
                        if url_match:
                            yield {"data": f"[SIGNAL_IMAGE_URL:{url_match.group(1)}]"}
                    elif tool_name == "generate_video":
                        url_match = re.search(r'\[System Hidden Video URL:\s*(https?://[^\s\]]+)\]', str(output))
                        if url_match:
                            yield {"data": f"[SIGNAL_VIDEO_URL:{url_match.group(1)}]"}

                # ğŸ’¬ å¸¸è§„æ¨¡å‹æ–‡æœ¬æµ
                elif kind == "on_chat_model_stream":
                    chunk = event["data"]["chunk"]
                    if chunk.content:
                        yield {"data": chunk.content}

        except Exception as e:
            print(f"âŒ Error in stream: {e}")
            yield {"data": f"[ERROR] {str(e)}"}
        finally:
            yield {"data": "[DONE]"}
            current_model_config.reset(token_config)
            current_image_data.reset(token_img)
            current_video_data.reset(token_vid)
            current_vision_model.reset(token_vision)

    return EventSourceResponse(event_generator())


@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    return {"filename": file.filename, "status": "success"}


@app.get("/knowledge_status")
async def get_knowledge_status(filename: str):
    from app.rag import knowledge_progress

    return knowledge_progress.get(filename, {"status": "not_found"})


@app.post("/upload_knowledge")
async def upload_knowledge(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    """
    æ¥æ”¶å‰ç«¯ä¸Šä¼ çš„æ–‡æ¡£ï¼Œè§£æå‡ºçº¯æ–‡æœ¬åé€å…¥ RAG çŸ¥è¯†åº“ï¼ˆåå°å¼‚æ­¥å…¥åº“ï¼Œç«‹å³è¿”å›ï¼‰
    """
    from app.rag import add_to_knowledge_base

    content = ""
    try:
        if file.filename.lower().endswith(".txt"):
            raw_bytes = await file.read()
            try:
                content = raw_bytes.decode("utf-8")
            except UnicodeDecodeError:
                try:
                    content = raw_bytes.decode("gb18030")
                except Exception as encode_err:
                    return {"status": "error", "message": f"âŒ æ–‡æœ¬ç¼–ç ä¸æ”¯æŒã€‚è¯·å°† TXT å¦å­˜ä¸º UTF-8 æ ¼å¼åé‡è¯•ã€‚æŠ¥é”™: {encode_err}"}
        elif file.filename.lower().endswith(".pdf"):
            import fitz

            raw_bytes = await file.read()
            with fitz.open(stream=raw_bytes, filetype="pdf") as pdf_document:
                for page_num in range(len(pdf_document)):
                    page = pdf_document[page_num]
                    text = page.get_text()
                    if text:
                        content += text + "\n"
        else:
            return {"status": "error", "message": "âŒ ä»…æ”¯æŒ TXT æˆ– PDF æ ¼å¼çš„æ–‡æ¡£"}

        if not content.strip():
            return {"status": "error", "message": "âŒ æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æ"}

        background_tasks.add_task(add_to_knowledge_base, content, file.filename)
        approx_chunks = max(1, len(content) // 500)
        return {
            "status": "success",
            "message": f"ğŸš€ æ–‡ä»¶å·²æ¥æ”¶ï¼å…±è®¡çº¦ {approx_chunks} ä¸ªçŸ¥è¯†å—æ­£åœ¨åå°å¼‚æ­¥æ³¨å…¥å¤§è„‘ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»ã€‚",
        }

    except Exception as e:
        print(f"è§£ææ–‡æ¡£å¼‚å¸¸: {e}")
        return {"status": "error", "message": f"âŒ è§£æå¤±è´¥: {str(e)}"}


if __name__ == "__main__":
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)