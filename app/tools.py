# app/tools.py
import os
import time
import base64
import tempfile
import cv2
import requests
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from tavily import TavilyClient
from app.rag import query_knowledge_base
from app.context import current_image_data, current_video_data, current_vision_model

# åˆå§‹åŒ–æœç´¢å®¢æˆ·ç«¯ (é˜²æ­¢ Key ç¼ºå¤±å¯¼è‡´å¯åŠ¨å´©æºƒï¼Œæ”¹ä¸ºè°ƒç”¨æ—¶æ£€æŸ¥)
tavily_api_key = os.getenv("TAVILY_API_KEY")
tavily_client = TavilyClient(api_key=tavily_api_key) if tavily_api_key else None


@tool
def web_search(query: str) -> str:
    """è”ç½‘æœç´¢å·¥å…·ï¼Œç”¨äºæŸ¥æ‰¾å®æ—¶ä¿¡æ¯ã€‚"""
    if not tavily_client:
        return "âŒ é”™è¯¯: æœªé…ç½® TAVILY_API_KEY"
    try:
        response = tavily_client.search(query=query, search_depth="advanced", max_results=5)
        results = response.get("results", [])
        if not results:
            return "æœªæœç´¢åˆ°ç›¸å…³ç»“æœã€‚"
        context = [f"ã€æ¥æº: {r['title']}ã€‘\n{r['content']}" for r in results]
        return "\n\n".join(context)
    except Exception as e:
        return f"æœç´¢æŠ¥é”™: {e}"


@tool
def search_knowledge_base(query: str) -> str:
    """æŸ¥é˜…æœ¬åœ°çŸ¥è¯†åº“"""
    try:
        result = query_knowledge_base(query, k=15)  # ç»™å¤§æ¨¡å‹æ›´å¤šçŸ¥è¯†å—
        return result if result else "çŸ¥è¯†åº“é‡Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"
    except Exception as e:
        return f"æŸ¥è¯¢æŠ¥é”™: {e}"


@tool
def generate_image(prompt: str) -> str:
    """
    AI ç»˜ç”»å·¥å…·ã€‚
    ã€æå…¶é‡è¦çš„è¦æ±‚ã€‘ï¼šæˆ‘ä»¬ç°åœ¨ä½¿ç”¨çš„æ˜¯çº¯å›½äº§è§†è§‰å¤§æ¨¡å‹ï¼Œå®ƒå¯¹ä¸­å›½ç¥è¯ã€ä¸œæ–¹ç¾å­¦å’Œä¸­æ–‡ä¿®è¾çš„ç†è§£æ˜¯åŸç”Ÿçš„ï¼
    å› æ­¤ï¼Œã€ç»å¯¹ç¦æ­¢ã€‘å°†ç”¨æˆ·çš„ä¸­æ–‡æç¤ºè¯ç¿»è¯‘æˆè‹±æ–‡ï¼è¯·ç›´æ¥ä½¿ç”¨ç»†èŠ‚ä¸°å¯Œã€ç”»é¢æ„Ÿå¼ºçš„ã€ä¸­æ–‡ Promptã€‘è°ƒç”¨æœ¬å·¥å…·ï¼ï¼ˆä¸è¦åœ¨å¯¹è¯æ¡†ä¸­æåŠæ­¤äº‹ï¼‰
    """
    print(f"ğŸ¨ [è°ƒç”¨è±†åŒ…ç”»å›¾] ä¸­æ–‡ Prompt: {prompt}")

    api_key = os.getenv("VOLC_API_KEY")
    endpoint_id = os.getenv("DOUBAO_IMAGE_ENDPOINT")

    if not api_key or not endpoint_id:
        return "âŒ é”™è¯¯: æœªé…ç½® VOLC_API_KEY æˆ– DOUBAO_IMAGE_ENDPOINTã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚"

    # ç«å±±å¼•æ“ç»Ÿä¸€å¤§æ¨¡å‹æ¨ç†æ¥å£
    url = "https://ark.cn-beijing.volces.com/api/v3/images/generations"
    payload = {
        "model": endpoint_id,
        "prompt": prompt
    }

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=60)

        if response.status_code == 200:
            data = response.json()
            image_url = data["data"][0]["url"]
            print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ (å·²è·å–é•¿é“¾æ¥)")

            # ğŸ›‘ æ ¸å¿ƒéšåŒ¿ä¿¡ä»¤æœºåˆ¶ï¼šæŠŠ URL è—åœ¨ç³»ç»Ÿæç¤ºé‡Œä¾›åç«¯æ­£åˆ™æå–ï¼Œä¸¥ä»¤å¤§æ¨¡å‹é—­å˜´
            return f"[System Hidden URL: {image_url}] Action Success! å›¾ç‰‡å·²æˆåŠŸåœ¨åå°æ¨é€ã€‚è¯·ç”¨è‡ªç„¶è¯­è¨€å‘Šè¯‰ç”¨æˆ·â€œå›¾ç‰‡å·²ä¸ºæ‚¨ç”Ÿæˆâ€ï¼Œã€ç»å¯¹ç¦æ­¢ã€‘åœ¨å›å¤ä¸­è¾“å‡ºä»»ä½• URL é“¾æ¥æˆ– Markdown ä»£ç ï¼"
        else:
            return f"API æŠ¥é”™ (çŠ¶æ€ç  {response.status_code}): {response.text}"

    except Exception as e:
        return f"ç”»å›¾è¯·æ±‚å¼‚å¸¸: {e}"


@tool
def generate_video(prompt: str) -> str:
    """
    è§†é¢‘ç”Ÿæˆå·¥å…·ï¼ˆé€ æ¢¦æœºï¼‰ã€‚
    å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚"ç”Ÿæˆè§†é¢‘"ã€"è®©ç”»é¢åŠ¨èµ·æ¥"ã€"åˆ¶ä½œçŸ­ç‰‡"æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
    ã€é‡è¦æç¤ºã€‘ï¼šæç¤ºè¯(prompt)å¿…é¡»æ˜¯æå…¶è¯¦ç»†çš„ä¸­æ–‡æè¿°ï¼Œéœ€åŒ…å«ï¼šä¸»ä½“æè¿°ã€ç¯å¢ƒèƒŒæ™¯ã€å…‰å½±æ°›å›´ï¼Œä»¥åŠã€é•œå¤´è¿åŠ¨ã€‘ï¼ˆå¦‚ï¼šé•œå¤´ç¼“æ…¢æ¨è¿›ã€å…¨æ™¯ç¯ç»•ç­‰ï¼‰ã€‚ç»å¯¹ç¦æ­¢ç¿»è¯‘ä¸ºè‹±æ–‡ã€‚
    """
    print(f"ğŸ¬ [è°ƒç”¨é€ æ¢¦æœº] æ­£åœ¨å‡†å¤‡å‘é€ä¸­æ–‡ Prompt: {prompt}", flush=True)

    api_key = os.getenv("VOLC_API_KEY")
    endpoint_id = os.getenv("DOUBAO_VIDEO_ENDPOINT")

    if not api_key or not endpoint_id:
        return "âŒ é”™è¯¯: æœªé…ç½® VOLC_API_KEY æˆ– DOUBAO_VIDEO_ENDPOINTã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚"

    # 1. ğŸš€ åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡
    create_url = "https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": endpoint_id,
        "content": [{"type": "text", "text": prompt}]
    }

    try:
        print("â³ æ­£åœ¨å‘ç«å±±å¼•æ“æäº¤è§†é¢‘ä»»åŠ¡...", flush=True)
        resp = requests.post(create_url, json=payload, headers=headers, timeout=30)
        if resp.status_code != 200:
            return f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥ (çŠ¶æ€ç  {resp.status_code}): {resp.text}"

        task_data = resp.json()
        task_id = task_data.get("id")
        if not task_id:
            return f"âŒ æœªèƒ½è·å–åˆ° Task ID: {task_data}"

        print(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸï¼ŒTask ID: {task_id}ã€‚å¼€å§‹è¿›è¡Œè½®è¯¢ç›‘å¬...", flush=True)

        # 2. ğŸ”„ è½®è¯¢ä»»åŠ¡çŠ¶æ€ (æ¯ 5 ç§’æŸ¥ä¸€æ¬¡ï¼Œæœ€å¤§ç­‰å¾… 6 åˆ†é’Ÿ)
        poll_url = f"https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks/{task_id}"
        max_attempts = 72  # 72 * 5ç§’ = 360ç§’

        for attempt in range(max_attempts):
            time.sleep(5)
            poll_resp = requests.get(poll_url, headers=headers, timeout=10)

            if poll_resp.status_code == 200:
                poll_data = poll_resp.json()
                status = poll_data.get("status")

                print(f"ğŸ”„ è½®è¯¢ç¬¬ {attempt+1} æ¬¡ï¼Œå½“å‰çŠ¶æ€: {status}", flush=True)

                if status == "succeeded":
                    # ğŸ›‘ æ ¸å¿ƒä¿®å¤ï¼šç«å±±å¼•æ“çš„ content æ˜¯å¯¹è±¡å­—å…¸ï¼Œç›´æ¥æå– video_url
                    content_obj = poll_data.get("content", {})
                    video_url = content_obj.get("video_url", "")

                    if video_url:
                        print(f"âœ… é€ æ¢¦æœºè§†é¢‘ç”ŸæˆæˆåŠŸï¼é•¿é“¾æ¥å·²è·å–: {video_url[:70]}...", flush=True)
                        return f"[System Hidden Video URL: {video_url}] Action Success! è§†é¢‘å·²åœ¨åå°æ¨é€ã€‚è¯·ç”¨è‡ªç„¶è¯­è¨€å‘Šè¯‰ç”¨æˆ·è§†é¢‘å·²ç”Ÿæˆï¼Œã€ç»å¯¹ç¦æ­¢ã€‘è¾“å‡º URL æˆ– Markdown ä»£ç ï¼"
                    else:
                        return f"âŒ ä»»åŠ¡æˆåŠŸï¼Œä½†æœªæ‰¾åˆ° video_urlã€‚è¿”å›ä½“: {poll_data}"

                elif status in ["failed", "canceled", "error"]:
                    return f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥æˆ–è¢«ç³»ç»Ÿæ‹¦æˆªï¼Œæœ€ç»ˆçŠ¶æ€: {status}ã€‚è¿”å›ä½“: {poll_data}"

                # status ä¸º 'queued' æˆ– 'running' æ—¶ï¼Œè·³è¿‡å½“å‰å¾ªç¯ï¼Œç»§ç»­ç­‰å¾…
            else:
                print(f"âš ï¸ è½®è¯¢è¯·æ±‚å¼‚å¸¸ (çŠ¶æ€ç  {poll_resp.status_code})ï¼Œç»§ç»­é‡è¯•...", flush=True)

        return "âŒ è§†é¢‘ç”Ÿæˆè¶…æ—¶ (è¶…è¿‡6åˆ†é’Ÿ)ã€‚ä»»åŠ¡å¯èƒ½ä»åœ¨ç«å±±åå°è¿è¡Œï¼Œè¯·ç¨åå‰å¾€æ§åˆ¶å°æŸ¥çœ‹ã€‚"

    except Exception as e:
        return f"é€ æ¢¦æœºè¯·æ±‚å¼‚å¸¸: {e}"


@tool
def analyze_uploaded_image(question: str) -> str:
    """
    è§†è§‰è§£æå·¥å…·ã€‚
    å½“ç”¨æˆ·è¦æ±‚ä½ â€œçœ‹å›¾â€ã€â€œåˆ†æå›¾ç‰‡â€æˆ–â€œæ ¹æ®ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œåˆ›ä½œ/ç”»å›¾â€æ—¶ï¼Œä½ å¿…é¡»ä¼˜å…ˆè°ƒç”¨æ­¤å·¥å…·ã€‚
    è¾“å…¥å‚æ•° question æ˜¯ä½ æƒ³è®©è§†è§‰ä¸­æ¢å¸®ä½ è§‚å¯Ÿçš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šâ€œè¯¦ç»†æè¿°å›¾ä¸­çš„äººç‰©ã€æ„å›¾ã€ç¾æœ¯é£æ ¼å’Œè‰²å½©â€ï¼‰ã€‚
    """
    base64_img = current_image_data.get()
    if not base64_img:
        return "âŒ è§†è§‰æ„ŸçŸ¥å¤±è´¥ï¼šå½“å‰ç¯å¢ƒæ²¡æœ‰æ£€æµ‹åˆ°ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ã€‚"

    vision_model_label = current_vision_model.get()
    print(f"ğŸ‘ï¸ [å”¤é†’è§†è§‰ä¸­æ¢] æ¨¡å‹: {vision_model_label} | æ¢é’ˆæé—®: {question}")

    try:
        if "Qwen" in vision_model_label:
            llm = ChatOpenAI(
                model="Qwen/Qwen2-VL-72B-Instruct",
                api_key=os.getenv("SILICONFLOW_API_KEY"),
                base_url="https://api.siliconflow.cn/v1",
                temperature=0.7,
            )
        else:
            llm = ChatOpenAI(
                model="glm-4v-plus",
                api_key=os.getenv("ZHIPU_API_KEY"),
                base_url="https://open.bigmodel.cn/api/paas/v4/",
                temperature=0.7,
            )

        content = [
            {"type": "text", "text": question},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}},
        ]
        res = llm.invoke([HumanMessage(content=content)])
        return f"è§†è§‰ä¸­æ¢è¿”å›çš„ç”»é¢ä¿¡æ¯ï¼š\n{res.content}\n\n[ç³»ç»Ÿåº•å±‚æŒ‡ä»¤ï¼šå›¾ç‰‡è§£æå·²å®Œæˆã€‚è¯·å›é¡¾ç”¨æˆ·çš„åŸå§‹æé—®ï¼Œå¦‚æœç”¨æˆ·åŒæ—¶è¦æ±‚äº†'ç”»å›¾'ã€'ç”Ÿæˆè§†é¢‘'æˆ–'å¤åˆ»'ç­‰éœ€è¦è°ƒç”¨ç”Ÿæˆå·¥å…·çš„è¯·æ±‚ï¼Œä½ å¿…é¡»åœ¨å½“å‰å¯¹è¯å›åˆå†…ï¼Œç«‹åˆ»æå–ä¸Šè¿°é£æ ¼ç»§ç»­è°ƒç”¨ generate_image æˆ– generate_video å·¥å…·ï¼Œç»å¯¹ä¸èƒ½ä¸­æ–­ç­‰å¾…ç”¨æˆ·å‚¬ä¿ƒï¼]"
    except Exception as e:
        return f"è§†è§‰è§£ææ¥å£æŠ¥é”™: {e}"


@tool
def analyze_uploaded_video(question: str) -> str:
    """
    è§†é¢‘è§£æå·¥å…·ã€‚
    å½“ç”¨æˆ·ä¸Šä¼ äº†è§†é¢‘ï¼Œå¹¶è¦æ±‚ä½ "çœ‹è§†é¢‘"ã€"åˆ†æè¿™æ®µè§†é¢‘"æˆ–"æå–è§†é¢‘æ–‡æ¡ˆ"æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
    è¾“å…¥å‚æ•° question æ˜¯ä½ æƒ³è®©è§†è§‰ä¸­æ¢å¸®ä½ è§‚å¯Ÿçš„å…·ä½“é‡ç‚¹ã€‚
    """
    base64_vid = current_video_data.get()
    if not base64_vid:
        return "âŒ è§†é¢‘è§£æå¤±è´¥ï¼šå½“å‰ç¯å¢ƒæ²¡æœ‰æ£€æµ‹åˆ°ç”¨æˆ·ä¸Šä¼ çš„è§†é¢‘ã€‚"

    vision_model_label = current_vision_model.get()
    print(f"ğŸ¥ [å”¤é†’è§†é¢‘ä¸­æ¢] æ¨¡å‹: {vision_model_label} | å¼€å§‹æŠ½å¸§è§£æ...", flush=True)

    video_bytes = base64.b64decode(base64_vid)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(video_bytes)
        tmp_path = tmp.name

    frames_b64 = []
    try:
        cap = cv2.VideoCapture(tmp_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total_frames > 0:
            num_frames = 8
            indices = [int(i * total_frames / num_frames) for i in range(num_frames)]

            for idx in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                if ret:
                    height, width = frame.shape[:2]
                    max_dim = 512
                    if max(height, width) > max_dim:
                        scale = max_dim / max(height, width)
                        frame = cv2.resize(frame, (int(width * scale), int(height * scale)))

                    _, buffer = cv2.imencode(".jpg", frame)
                    frames_b64.append(base64.b64encode(buffer).decode("utf-8"))
        cap.release()
    finally:
        os.remove(tmp_path)

    if not frames_b64:
        return "âŒ è§†é¢‘æŠ½å¸§å¤±è´¥ï¼Œæ— æ³•è¯»å–ç”»é¢ã€‚"

    try:
        if "Qwen" in vision_model_label:
            llm = ChatOpenAI(
                model="Qwen/Qwen2-VL-72B-Instruct",
                api_key=os.getenv("SILICONFLOW_API_KEY"),
                base_url="https://api.siliconflow.cn/v1",
                temperature=0.7,
            )
        else:
            llm = ChatOpenAI(
                model="glm-4v-plus",
                api_key=os.getenv("ZHIPU_API_KEY"),
                base_url="https://open.bigmodel.cn/api/paas/v4/",
                temperature=0.7,
            )

        content = [{"type": "text", "text": f"{question} (ä»¥ä¸‹æ˜¯è¯¥è§†é¢‘æŒ‰æ—¶é—´é¡ºåºæŠ½å–çš„ {len(frames_b64)} å¼ å…³é”®å¸§ç”»é¢ï¼Œè¯·ç»¼åˆè¿™äº›ç”»é¢æ¨æ–­è§†é¢‘å‘ç”Ÿçš„æ•…äº‹å’ŒåŠ¨æ€ç»†èŠ‚)ï¼š"}]
        for b64 in frames_b64:
            content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})

        res = llm.invoke([HumanMessage(content=content)])
        return f"è§†é¢‘è§†è§‰ä¸­æ¢è¿”å›çš„æ·±åº¦è§£ææŠ¥å‘Šï¼š\n{res.content}\n\n[ç³»ç»Ÿåº•å±‚æŒ‡ä»¤ï¼šè§†é¢‘è§£æå·²å®Œæˆã€‚è¯·å›é¡¾ç”¨æˆ·çš„åŸå§‹æé—®ï¼Œå¦‚æœç”¨æˆ·åŒæ—¶è¦æ±‚äº†'ç”»å›¾'ã€'ç”Ÿæˆè§†é¢‘'æˆ–'å¤åˆ»'ç­‰éœ€è¦è°ƒç”¨ç”Ÿæˆå·¥å…·çš„è¯·æ±‚ï¼Œä½ å¿…é¡»åœ¨å½“å‰å¯¹è¯å›åˆå†…ï¼Œç«‹åˆ»åŸºäºä¸Šè¿°æŠ¥å‘Šç»§ç»­è°ƒç”¨ generate_image æˆ– generate_video å·¥å…·ï¼Œç»å¯¹ä¸èƒ½ä¸­æ–­ç­‰å¾…ç”¨æˆ·å‚¬ä¿ƒï¼]"
    except Exception as e:
        return f"è§†è§‰è§£ææ¥å£æŠ¥é”™: {e}"


# å¯¼å‡ºå·¥å…·åˆ—è¡¨
tools = [web_search, search_knowledge_base, generate_image, generate_video, analyze_uploaded_image, analyze_uploaded_video]
